{"filename":"src/lib/snark_keys_header/snark_keys_header.ml","lines":[{"line":"open Core_kernel","counters":[]},{"line":"","counters":[]},{"line":"(** The string that preceeds the JSON header, to identify the file kind before","counters":[]},{"line":"    attempting to parse it.","counters":[]},{"line":"*)","counters":[]},{"line":"let header_string = \"MINA_SNARK_KEYS\\n\"","counters":[]},{"line":"","counters":[]},{"line":"module UInt64 = struct","counters":[]},{"line":"  (* [Unsigned_extended] depends on pickles, manually include what we need here","counters":[]},{"line":"     to break a dependency cycle","counters":[]},{"line":"","counters":[]},{"line":"     TODO: Separate [Unsigned_extended] into snark and non-snark parts.","counters":[]},{"line":"  *)","counters":[]},{"line":"  type t = Unsigned.UInt64.t [@@deriving ord, equal]","counters":[{"col_start":2,"col_end":2,"count":0},{"col_start":11,"col_end":11,"count":0},{"col_start":51,"col_end":51,"count":0}]},{"line":"","counters":[]},{"line":"  let to_yojson x = `String (Unsigned.UInt64.to_string x)","counters":[{"col_start":20,"col_end":20,"count":0},{"col_start":53,"col_end":53,"count":0}]},{"line":"","counters":[]},{"line":"  let of_yojson = function","counters":[]},{"line":"    | `String x ->","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"        Or_error.try_with (fun () -> Unsigned.UInt64.of_string x)","counters":[{"col_start":37,"col_end":37,"count":0}]},{"line":"        |> Result.map_error ~f:(fun err ->","counters":[{"col_start":11,"col_end":11,"count":0}]},{"line":"               sprintf","counters":[{"col_start":15,"col_end":15,"count":0}]},{"line":"                 \"Snark_keys_header.UInt64.of_yojson: Could not parse string \\","counters":[]},{"line":"                  as UInt64: %s\"","counters":[]},{"line":"                 (Error.to_string_hum err) )","counters":[{"col_start":36,"col_end":36,"count":0}]},{"line":"    | _ ->","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"        Error \"Snark_keys_header.UInt64.of_yojson: Expected a string\"","counters":[]},{"line":"","counters":[]},{"line":"  let sexp_of_t x = Sexp.Atom (Unsigned.UInt64.to_string x)","counters":[{"col_start":20,"col_end":20,"count":0},{"col_start":55,"col_end":55,"count":0}]},{"line":"","counters":[]},{"line":"  let t_of_sexp = function","counters":[]},{"line":"    | Sexp.Atom x ->","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"        Unsigned.UInt64.of_string x","counters":[]},{"line":"    | _ ->","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"        failwith \"Snark_keys_header.UInt64.t_of_sexp: Expected an atom\"","counters":[]},{"line":"end","counters":[]},{"line":"","counters":[]},{"line":"module Kind = struct","counters":[]},{"line":"  (** The 'kind' of data in the file.","counters":[]},{"line":"    For example, a step proving key for the base transaction snark may have the","counters":[]},{"line":"    kind:","counters":[]},{"line":"{[","counters":[]},{"line":"  {type_= \"step_proving_key\"; identifier= \"transaction_snark_base\"}","counters":[]},{"line":"|}","counters":[]},{"line":"  *)","counters":[]},{"line":"  type t =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    { type_ : string [@key \"type\"]","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":10,"col_end":10,"count":0},{"col_start":14,"col_end":14,"count":0},{"col_start":19,"col_end":19,"count":0}]},{"line":"          (** Identifies the type of data that the file contains *)","counters":[]},{"line":"    ; identifier : string","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":15,"col_end":15,"count":0},{"col_start":19,"col_end":19,"count":0},{"col_start":24,"col_end":24,"count":0}]},{"line":"          (** Identifies the specific purpose of the file's data, in a","counters":[]},{"line":"            human-readable format","counters":[]},{"line":"        *)","counters":[]},{"line":"    }","counters":[]},{"line":"  [@@deriving yojson, sexp, ord, equal]","counters":[{"col_start":38,"col_end":38,"count":0}]},{"line":"end","counters":[]},{"line":"","counters":[]},{"line":"module Constraint_constants = struct","counters":[]},{"line":"  module Transaction_capacity = struct","counters":[]},{"line":"    (** Transaction pool capacity *)","counters":[]},{"line":"    type t = Log_2 of int | Txns_per_second_x10 of int","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":13,"col_end":13,"count":0},{"col_start":22,"col_end":22,"count":0},{"col_start":26,"col_end":26,"count":0},{"col_start":51,"col_end":51,"count":0}]},{"line":"    [@@deriving sexp, ord, equal]","counters":[{"col_start":32,"col_end":32,"count":0}]},{"line":"","counters":[]},{"line":"    let to_yojson t : Yojson.Safe.t =","counters":[]},{"line":"      match t with","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      | Log_2 i ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          `Assoc [ (\"two_to_the\", `Int i) ]","counters":[]},{"line":"      | Txns_per_second_x10 i ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          `Assoc [ (\"txns_per_second_x10\", `Int i) ]","counters":[]},{"line":"","counters":[]},{"line":"    let of_yojson (json : Yojson.Safe.t) =","counters":[]},{"line":"      match json with","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      | `Assoc [ (\"two_to_the\", `Int i) ] ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Ok (Log_2 i)","counters":[]},{"line":"      | `Assoc [ (\"txns_per_second_x10\", `Int i) ] ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Ok (Txns_per_second_x10 i)","counters":[]},{"line":"      | `Assoc _ ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Error","counters":[]},{"line":"            \"Snark_keys_header.Constraint_constants.Transaction_capacity.of_yojson: \\","counters":[]},{"line":"             Expected a JSON object containing the field 'two_to_the' or \\","counters":[]},{"line":"             'txns_per_second_x10'\"","counters":[]},{"line":"      | _ ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Error","counters":[]},{"line":"            \"Snark_keys_header.Constraint_constants.Transaction_capacity.of_yojson: \\","counters":[]},{"line":"             Expected a JSON object\"","counters":[]},{"line":"  end","counters":[]},{"line":"","counters":[]},{"line":"  module Fork_config = struct","counters":[]},{"line":"    (** Fork data *)","counters":[]},{"line":"    type t =","counters":[{"col_start":4,"col_end":4,"count":0}]},{"line":"      { previous_state_hash : string","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":26,"col_end":26,"count":0},{"col_start":30,"col_end":30,"count":0},{"col_start":35,"col_end":35,"count":0}]},{"line":"      ; previous_length : int","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":22,"col_end":22,"count":0},{"col_start":26,"col_end":26,"count":0},{"col_start":28,"col_end":28,"count":0}]},{"line":"      ; previous_global_slot : int","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":27,"col_end":27,"count":0},{"col_start":31,"col_end":31,"count":0},{"col_start":33,"col_end":33,"count":0}]},{"line":"      }","counters":[]},{"line":"    [@@deriving yojson, sexp, ord, equal]","counters":[{"col_start":40,"col_end":40,"count":0}]},{"line":"","counters":[]},{"line":"    let opt_to_yojson t : Yojson.Safe.t =","counters":[]},{"line":"      match t with Some t -> to_yojson t | None -> `Assoc []","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":19,"col_end":19,"count":0},{"col_start":43,"col_end":43,"count":0}]},{"line":"","counters":[]},{"line":"    let opt_of_yojson (json : Yojson.Safe.t) =","counters":[]},{"line":"      match json with","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      | `Assoc [] ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Ok None","counters":[]},{"line":"      | _ ->","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          Result.map (of_yojson json) ~f:(fun t -> Some t)","counters":[{"col_start":30,"col_end":30,"count":0},{"col_start":51,"col_end":51,"count":0}]},{"line":"  end","counters":[]},{"line":"","counters":[]},{"line":"  (** The constants used in the constraint system.  *)","counters":[]},{"line":"  type t =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    { sub_windows_per_window : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":27,"col_end":27,"count":0},{"col_start":31,"col_end":31,"count":0},{"col_start":33,"col_end":33,"count":0}]},{"line":"    ; ledger_depth : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":17,"col_end":17,"count":0},{"col_start":21,"col_end":21,"count":0},{"col_start":23,"col_end":23,"count":0}]},{"line":"    ; work_delay : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":15,"col_end":15,"count":0},{"col_start":19,"col_end":19,"count":0},{"col_start":21,"col_end":21,"count":0}]},{"line":"    ; block_window_duration_ms : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":29,"col_end":29,"count":0},{"col_start":33,"col_end":33,"count":0},{"col_start":35,"col_end":35,"count":0}]},{"line":"    ; transaction_capacity : Transaction_capacity.t","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":25,"col_end":25,"count":0},{"col_start":29,"col_end":29,"count":0},{"col_start":50,"col_end":50,"count":0}]},{"line":"    ; pending_coinbase_depth : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":27,"col_end":27,"count":0},{"col_start":31,"col_end":31,"count":0},{"col_start":33,"col_end":33,"count":0}]},{"line":"    ; coinbase_amount : UInt64.t","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":20,"col_end":20,"count":0},{"col_start":24,"col_end":24,"count":0},{"col_start":31,"col_end":31,"count":0}]},{"line":"    ; supercharged_coinbase_factor : int","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":33,"col_end":33,"count":0},{"col_start":37,"col_end":37,"count":0},{"col_start":39,"col_end":39,"count":0}]},{"line":"    ; account_creation_fee : UInt64.t","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":25,"col_end":25,"count":0},{"col_start":29,"col_end":29,"count":0},{"col_start":36,"col_end":36,"count":0}]},{"line":"    ; fork :","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":9,"col_end":9,"count":0}]},{"line":"        (Fork_config.t option","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"        [@to_yojson Fork_config.opt_to_yojson]","counters":[{"col_start":44,"col_end":44,"count":0}]},{"line":"        [@of_yojson Fork_config.opt_of_yojson] )","counters":[{"col_start":44,"col_end":44,"count":0}]},{"line":"    }","counters":[]},{"line":"  [@@deriving yojson, sexp, ord, equal]","counters":[{"col_start":38,"col_end":38,"count":0}]},{"line":"end","counters":[]},{"line":"","counters":[]},{"line":"module Commits = struct","counters":[]},{"line":"  (** Commit identifiers *)","counters":[]},{"line":"  type t = { mina : string; marlin : string }","counters":[{"col_start":2,"col_end":2,"count":0},{"col_start":13,"col_end":13,"count":0},{"col_start":16,"col_end":16,"count":0},{"col_start":20,"col_end":20,"count":0},{"col_start":25,"col_end":25,"count":0},{"col_start":28,"col_end":28,"count":0},{"col_start":33,"col_end":33,"count":0},{"col_start":37,"col_end":37,"count":0},{"col_start":42,"col_end":42,"count":0}]},{"line":"  [@@deriving yojson, sexp, ord, equal]","counters":[{"col_start":38,"col_end":38,"count":0}]},{"line":"end","counters":[]},{"line":"","counters":[]},{"line":"let header_version = 1","counters":[]},{"line":"","counters":[]},{"line":"(** Header contents *)","counters":[]},{"line":"type t =","counters":[{"col_start":0,"col_end":0,"count":0}]},{"line":"  { header_version : int","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":17,"col_end":17,"count":0},{"col_start":21,"col_end":21,"count":0},{"col_start":23,"col_end":23,"count":0}]},{"line":"  ; kind : Kind.t","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":7,"col_end":7,"count":0},{"col_start":11,"col_end":11,"count":0},{"col_start":16,"col_end":16,"count":0}]},{"line":"  ; constraint_constants : Constraint_constants.t","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":23,"col_end":23,"count":0},{"col_start":27,"col_end":27,"count":0},{"col_start":48,"col_end":48,"count":0}]},{"line":"  ; commits : Commits.t","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":10,"col_end":10,"count":0},{"col_start":14,"col_end":14,"count":0},{"col_start":22,"col_end":22,"count":0}]},{"line":"  ; length : int","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":9,"col_end":9,"count":0},{"col_start":13,"col_end":13,"count":0},{"col_start":15,"col_end":15,"count":0}]},{"line":"  ; commit_date : string","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":14,"col_end":14,"count":0},{"col_start":18,"col_end":18,"count":0},{"col_start":23,"col_end":23,"count":0}]},{"line":"  ; constraint_system_hash : string","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":25,"col_end":25,"count":0},{"col_start":29,"col_end":29,"count":0},{"col_start":34,"col_end":34,"count":0}]},{"line":"  ; identifying_hash : string","counters":[{"col_start":4,"col_end":4,"count":0},{"col_start":19,"col_end":19,"count":0},{"col_start":23,"col_end":23,"count":0},{"col_start":28,"col_end":28,"count":0}]},{"line":"  }","counters":[]},{"line":"[@@deriving yojson, sexp, ord, equal]","counters":[{"col_start":36,"col_end":36,"count":0}]},{"line":"","counters":[]},{"line":"let prefix = \"MINA_SNARK_KEYS\\n\"","counters":[]},{"line":"","counters":[]},{"line":"let prefix_len = String.length prefix","counters":[{"col_start":29,"col_end":29,"count":1}]},{"line":"","counters":[]},{"line":"let parse_prefix (lexbuf : Lexing.lexbuf) =","counters":[]},{"line":"  let open Or_error.Let_syntax in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  Result.map_error ~f:(fun err ->","counters":[]},{"line":"      Error.tag_arg err \"Could not read prefix\" (\"prefix\", prefix)","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"        [%sexp_of: string * string] )","counters":[]},{"line":"  @@ Or_error.try_with_join (fun () ->","counters":[{"col_start":26,"col_end":26,"count":0}]},{"line":"         (* This roughly mirrors the behavior of [Yojson.Safe.read_ident],","counters":[]},{"line":"            except that we have a known fixed length to parse, and that it is a","counters":[]},{"line":"            failure to read any string except the prefix. We manually update","counters":[]},{"line":"            the lexbuf to be consistent with the output of this function.","counters":[]},{"line":"         *)","counters":[]},{"line":"         (* Manually step the lexbuffer forward to the [lex_curr_pos], so that","counters":[]},{"line":"            [refill_buf] will know that we're only interested in buffer","counters":[]},{"line":"            contents from that position onwards.","counters":[]},{"line":"         *)","counters":[]},{"line":"         lexbuf.lex_start_pos <- lexbuf.lex_curr_pos ;","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"         lexbuf.lex_last_pos <- lexbuf.lex_curr_pos ;","counters":[]},{"line":"         lexbuf.lex_start_p <- lexbuf.lex_curr_p ;","counters":[]},{"line":"         let%bind () =","counters":[]},{"line":"           (* Read more if the buffer doesn't contain the whole prefix. *)","counters":[]},{"line":"           if lexbuf.lex_buffer_len - lexbuf.lex_curr_pos >= prefix_len then","counters":[]},{"line":"             return ()","counters":[{"col_start":13,"col_end":13,"count":0},{"col_start":18,"col_end":18,"count":0}]},{"line":"           else if lexbuf.lex_eof_reached then","counters":[{"col_start":16,"col_end":16,"count":0}]},{"line":"             Or_error.error_string \"Unexpected end-of-file\"","counters":[{"col_start":13,"col_end":13,"count":0},{"col_start":33,"col_end":33,"count":0}]},{"line":"           else (","counters":[{"col_start":16,"col_end":16,"count":0}]},{"line":"             lexbuf.refill_buff lexbuf ;","counters":[]},{"line":"             if lexbuf.lex_buffer_len - lexbuf.lex_curr_pos >= prefix_len then","counters":[{"col_start":13,"col_end":13,"count":0}]},{"line":"               return ()","counters":[{"col_start":15,"col_end":15,"count":0},{"col_start":20,"col_end":20,"count":0}]},{"line":"             else if lexbuf.lex_eof_reached then","counters":[{"col_start":18,"col_end":18,"count":0}]},{"line":"               Or_error.error_string \"Unexpected end-of-file\"","counters":[{"col_start":15,"col_end":15,"count":0},{"col_start":35,"col_end":35,"count":0}]},{"line":"             else","counters":[]},{"line":"               Or_error.error_string","counters":[{"col_start":15,"col_end":15,"count":0},{"col_start":35,"col_end":35,"count":0}]},{"line":"                 \"Unexpected short read: broken lexbuffer or end-of-file\" )","counters":[]},{"line":"         in","counters":[]},{"line":"         let read_prefix =","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"           Lexing.sub_lexeme lexbuf lexbuf.lex_curr_pos","counters":[]},{"line":"             (lexbuf.lex_curr_pos + prefix_len)","counters":[]},{"line":"         in","counters":[]},{"line":"         let%map () =","counters":[]},{"line":"           if String.equal prefix read_prefix then return ()","counters":[{"col_start":51,"col_end":51,"count":0},{"col_start":56,"col_end":56,"count":0}]},{"line":"           else","counters":[]},{"line":"             Or_error.error \"Incorrect prefix\"","counters":[{"col_start":13,"col_end":13,"count":0},{"col_start":26,"col_end":26,"count":0}]},{"line":"               (\"read prefix\", read_prefix)","counters":[]},{"line":"               [%sexp_of: string * string]","counters":[]},{"line":"         in","counters":[]},{"line":"         (* Update the positions to match our end state *)","counters":[]},{"line":"         lexbuf.lex_curr_pos <- lexbuf.lex_curr_pos + prefix_len ;","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"         lexbuf.lex_last_pos <- lexbuf.lex_last_pos ;","counters":[]},{"line":"         lexbuf.lex_curr_p <-","counters":[]},{"line":"           { lexbuf.lex_curr_p with","counters":[]},{"line":"             pos_bol = lexbuf.lex_curr_p.pos_bol + prefix_len","counters":[]},{"line":"           ; pos_cnum = lexbuf.lex_curr_p.pos_cnum + prefix_len","counters":[]},{"line":"           } ;","counters":[]},{"line":"         (* This matches the action given by [Yojson.Safe.read_ident]. *)","counters":[]},{"line":"         lexbuf.lex_last_action <- 1 )","counters":[]},{"line":"","counters":[]},{"line":"let parse_lexbuf (lexbuf : Lexing.lexbuf) =","counters":[]},{"line":"  let open Or_error.Let_syntax in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  Result.map_error ~f:(Error.tag ~tag:\"Failed to read snark key header\")","counters":[]},{"line":"  @@ let%bind () = parse_prefix lexbuf in","counters":[{"col_start":30,"col_end":30,"count":0}]},{"line":"     Or_error.try_with (fun () ->","counters":[{"col_start":5,"col_end":5,"count":0}]},{"line":"         let yojson_parsebuffer = Yojson.init_lexer () in","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"         (* We use [read_t] here rather than one of the alternatives to avoid","counters":[]},{"line":"            'greedy' parsing that will attempt to continue and read the file's","counters":[]},{"line":"            contents beyond the header.","counters":[]},{"line":"         *)","counters":[]},{"line":"         Yojson.Safe.read_t yojson_parsebuffer lexbuf )","counters":[{"col_start":9,"col_end":9,"count":0}]},{"line":"","counters":[]},{"line":"let%test_module \"Check parsing of header\" =","counters":[]},{"line":"  ( module struct","counters":[]},{"line":"    let valid_header =","counters":[]},{"line":"      { header_version = 1","counters":[]},{"line":"      ; kind = { type_ = \"type\"; identifier = \"identifier\" }","counters":[]},{"line":"      ; constraint_constants =","counters":[]},{"line":"          { sub_windows_per_window = 4","counters":[]},{"line":"          ; ledger_depth = 8","counters":[]},{"line":"          ; work_delay = 1000","counters":[]},{"line":"          ; block_window_duration_ms = 1000","counters":[]},{"line":"          ; transaction_capacity = Log_2 3","counters":[]},{"line":"          ; pending_coinbase_depth = 12","counters":[]},{"line":"          ; coinbase_amount = Unsigned.UInt64.of_int 1","counters":[{"col_start":51,"col_end":51,"count":0}]},{"line":"          ; supercharged_coinbase_factor = 1","counters":[]},{"line":"          ; account_creation_fee = Unsigned.UInt64.of_int 1","counters":[{"col_start":56,"col_end":56,"count":0}]},{"line":"          ; fork = None","counters":[]},{"line":"          }","counters":[]},{"line":"      ; commits =","counters":[]},{"line":"          { mina = \"7e1fb2cd9138af1d0f24e78477efd40a2a0fcd07\"","counters":[]},{"line":"          ; marlin = \"75836c41fc4947acce9c938da1b2f506843e90ed\"","counters":[]},{"line":"          }","counters":[]},{"line":"      ; length = 4096","counters":[]},{"line":"      ; commit_date = \"2020-01-01 00:00:00.000000Z\"","counters":[]},{"line":"      ; constraint_system_hash = \"ABCDEF1234567890\"","counters":[]},{"line":"      ; identifying_hash = \"ABCDEF1234567890\"","counters":[]},{"line":"      }","counters":[]},{"line":"","counters":[]},{"line":"    let valid_header_string = Yojson.Safe.to_string (to_yojson valid_header)","counters":[{"col_start":50,"col_end":50,"count":0},{"col_start":61,"col_end":61,"count":0}]},{"line":"","counters":[]},{"line":"    let valid_header_with_prefix = prefix ^ valid_header_string","counters":[]},{"line":"","counters":[]},{"line":"    module Tests (Lexing : sig","counters":[]},{"line":"      val from_string : ?with_positions:bool -> string -> Lexing.lexbuf","counters":[]},{"line":"    end) =","counters":[]},{"line":"    struct","counters":[]},{"line":"      let%test \"doesn't parse without prefix\" =","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string valid_header_string)","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0}]},{"line":"        |> Or_error.is_error","counters":[{"col_start":11,"col_end":11,"count":0}]},{"line":"","counters":[]},{"line":"      let%test \"doesn't parse with incorrect prefix\" =","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string (\"BLAH\" ^ valid_header_string))","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0}]},{"line":"        |> Or_error.is_error","counters":[{"col_start":11,"col_end":11,"count":0}]},{"line":"","counters":[]},{"line":"      let%test \"doesn't parse with matching-length prefix\" =","counters":[]},{"line":"        let fake_prefix = String.init prefix_len ~f:(fun _ -> 'a') in","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":62,"col_end":62,"count":0}]},{"line":"        parse_lexbuf (Lexing.from_string (fake_prefix ^ valid_header_string))","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0}]},{"line":"        |> Or_error.is_error","counters":[{"col_start":11,"col_end":11,"count":0}]},{"line":"","counters":[]},{"line":"      let%test \"doesn't parse with partial matching prefix\" =","counters":[]},{"line":"        let partial_prefix =","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          String.sub prefix ~pos:0 ~len:(prefix_len - 1) ^ \" \"","counters":[{"col_start":19,"col_end":19,"count":0}]},{"line":"        in","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string (partial_prefix ^ valid_header_string))","counters":[{"col_start":39,"col_end":39,"count":0}]},{"line":"        |> Or_error.is_error","counters":[{"col_start":11,"col_end":11,"count":0}]},{"line":"","counters":[]},{"line":"      let%test \"doesn't parse with short file\" =","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string \"BLAH\") |> Or_error.is_error","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0},{"col_start":52,"col_end":52,"count":0}]},{"line":"","counters":[]},{"line":"      let%test \"doesn't parse with prefix only\" =","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string prefix) |> Or_error.is_error","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0},{"col_start":52,"col_end":52,"count":0}]},{"line":"","counters":[]},{"line":"      let%test_unit \"parses valid header with prefix\" =","counters":[]},{"line":"        parse_lexbuf (Lexing.from_string valid_header_with_prefix)","counters":[{"col_start":8,"col_end":8,"count":0},{"col_start":39,"col_end":39,"count":0}]},{"line":"        |> Or_error.ok_exn |> ignore","counters":[{"col_start":11,"col_end":11,"count":0},{"col_start":30,"col_end":30,"count":0}]},{"line":"","counters":[]},{"line":"      let%test_unit \"parses valid header with prefix and data\" =","counters":[]},{"line":"        parse_lexbuf","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"          (Lexing.from_string (valid_header_with_prefix ^ \"DATADATADATA\"))","counters":[{"col_start":28,"col_end":28,"count":0}]},{"line":"        |> Or_error.ok_exn |> ignore","counters":[{"col_start":11,"col_end":11,"count":0},{"col_start":30,"col_end":30,"count":0}]},{"line":"    end","counters":[]},{"line":"","counters":[]},{"line":"    let%test_module \"Parsing from the start of the lexbuf\" =","counters":[]},{"line":"      (module Tests (Lexing))","counters":[]},{"line":"","counters":[]},{"line":"    let%test_module \"Parsing from part-way through a lexbuf\" =","counters":[]},{"line":"      ( module struct","counters":[]},{"line":"        include Tests (struct","counters":[]},{"line":"          let from_string ?with_positions:_ str =","counters":[]},{"line":"            let prefix = \"AAAAAAAAAA\" in","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            let prefix_len = String.length prefix in","counters":[]},{"line":"            let lexbuf = Lexing.from_string (prefix ^ str) in","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            lexbuf.lex_start_pos <- 0 ;","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            lexbuf.lex_curr_pos <- prefix_len ;","counters":[]},{"line":"            lexbuf.lex_last_pos <- prefix_len ;","counters":[]},{"line":"            lexbuf","counters":[]},{"line":"        end)","counters":[]},{"line":"      end )","counters":[]},{"line":"","counters":[]},{"line":"    let%test_module \"Parsing with refill\" =","counters":[]},{"line":"      ( module struct","counters":[]},{"line":"        include Tests (struct","counters":[]},{"line":"          let from_string ?with_positions:_ str =","counters":[]},{"line":"            let init = ref true in","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            let initial_prefix = \"AAAAAAAAAA\" in","counters":[]},{"line":"            let initial_prefix_len = String.length initial_prefix in","counters":[]},{"line":"            let offset = ref 0 in","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            let str_len = String.length str in","counters":[]},{"line":"            let lexbuf =","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"              Lexing.from_function (fun buffer length ->","counters":[]},{"line":"                  match !init with","counters":[{"col_start":18,"col_end":18,"count":0}]},{"line":"                  | true ->","counters":[{"col_start":20,"col_end":20,"count":0}]},{"line":"                      init := false ;","counters":[]},{"line":"                      (* Initial read: fill with junk up to the first character","counters":[]},{"line":"                         of the actual prefix","counters":[]},{"line":"                      *)","counters":[]},{"line":"                      Bytes.From_string.blit ~src:initial_prefix ~src_pos:0","counters":[]},{"line":"                        ~dst:buffer ~dst_pos:0 ~len:initial_prefix_len ;","counters":[]},{"line":"                      Bytes.set buffer initial_prefix_len str.[0] ;","counters":[]},{"line":"                      offset := 1 ;","counters":[{"col_start":22,"col_end":22,"count":0}]},{"line":"                      initial_prefix_len + 1","counters":[]},{"line":"                  | false ->","counters":[{"col_start":20,"col_end":20,"count":0}]},{"line":"                      (* Subsequent read: fill the rest of the buffer. *)","counters":[]},{"line":"                      let len = Int.min length (str_len - !offset) in","counters":[]},{"line":"                      if len = 0 then 0","counters":[{"col_start":22,"col_end":22,"count":0},{"col_start":38,"col_end":38,"count":0}]},{"line":"                      else (","counters":[{"col_start":27,"col_end":27,"count":0}]},{"line":"                        Bytes.From_string.blit ~src:str ~src_pos:!offset","counters":[]},{"line":"                          ~dst:buffer ~dst_pos:0 ~len ;","counters":[]},{"line":"                        offset := !offset + len ;","counters":[]},{"line":"                        len ) )","counters":[]},{"line":"            in","counters":[]},{"line":"            (* Load the initial content into the buffer *)","counters":[]},{"line":"            lexbuf.refill_buff lexbuf ;","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            lexbuf.lex_start_pos <- 0 ;","counters":[{"col_start":12,"col_end":12,"count":0}]},{"line":"            lexbuf.lex_curr_pos <- initial_prefix_len ;","counters":[]},{"line":"            lexbuf.lex_last_pos <- initial_prefix_len ;","counters":[]},{"line":"            lexbuf","counters":[]},{"line":"        end)","counters":[]},{"line":"      end )","counters":[]},{"line":"  end )","counters":[]},{"line":"","counters":[]},{"line":"let write_with_header ~expected_max_size_log2 ~append_data header filename =","counters":[]},{"line":"  (* In order to write the correct length here, we provide the maximum expected","counters":[]},{"line":"     size and store that in the initial header. Once the data has been written,","counters":[]},{"line":"     we record the length and then modify the 'length' field to hold the","counters":[]},{"line":"     correct data.","counters":[]},{"line":"     Happily, since the header is JSON-encoded, we can pad the calculated","counters":[]},{"line":"     length with spaces and the header will still form a valid JSON-encoded","counters":[]},{"line":"     object.","counters":[]},{"line":"     This intuitively feels hacky, but the only way this can fail are if we are","counters":[]},{"line":"     not able to write all of our data to the filesystem, or if the file is","counters":[]},{"line":"     modified during the writing process. In either of these cases, we would","counters":[]},{"line":"     have the same issue even if we were to pre-compute the length and do the","counters":[]},{"line":"     write atomically.","counters":[]},{"line":"  *)","counters":[]},{"line":"  let length = 1 lsl expected_max_size_log2 in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  if length <= 0 then","counters":[]},{"line":"    failwith","counters":[{"col_start":4,"col_end":4,"count":0}]},{"line":"      \"Snark_keys_header.write_header: expected_max_size_log2 is too large, \\","counters":[]},{"line":"       the resulting length underflows\" ;","counters":[]},{"line":"  let header_string =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    Yojson.Safe.to_string (to_yojson { header with length })","counters":[{"col_start":35,"col_end":35,"count":0}]},{"line":"  in","counters":[]},{"line":"  (* We look for the \"length\" field first, to ensure that we find our length","counters":[]},{"line":"     and not some other data that happens to match it. Due to the","counters":[]},{"line":"     JSON-encoding, we will only find the first field named \"length\", which is","counters":[]},{"line":"     the one that we want to modify.","counters":[]},{"line":"  *)","counters":[]},{"line":"  let length_offset =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    String.substr_index_exn header_string ~pattern:\"\\\"length\\\":\"","counters":[]},{"line":"  in","counters":[]},{"line":"  let length_string = string_of_int length in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  let length_data_offset =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    prefix_len","counters":[]},{"line":"    + String.substr_index_exn ~pos:length_offset header_string","counters":[{"col_start":28,"col_end":28,"count":0}]},{"line":"        ~pattern:length_string","counters":[]},{"line":"  in","counters":[]},{"line":"  (* We use [binary=true] to ensure that line endings aren't converted, so that","counters":[]},{"line":"     files can be used regardless of the operating system that generated them.","counters":[]},{"line":"  *)","counters":[]},{"line":"  Out_channel.with_file ~binary:true filename ~f:(fun out_channel ->","counters":[]},{"line":"      Out_channel.output_string out_channel prefix ;","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      Out_channel.output_string out_channel header_string ;","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      (* Newline, to allow [head -n 2 path/to/file | tail -n 1] to easily","counters":[]},{"line":"         extract the header.","counters":[]},{"line":"      *)","counters":[]},{"line":"      Out_channel.output_char out_channel '\\n' ) ;","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"  append_data filename ;","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  (* Core doesn't let us open a file without appending or truncating, so we use","counters":[]},{"line":"     stdlib instead.","counters":[]},{"line":"  *)","counters":[]},{"line":"  let out_channel =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    Stdlib.open_out_gen [ Open_wronly; Open_binary ] 0 filename","counters":[]},{"line":"  in","counters":[]},{"line":"  let true_length = Out_channel.length out_channel |> Int.of_int64_exn in","counters":[{"col_start":2,"col_end":2,"count":0},{"col_start":54,"col_end":54,"count":0}]},{"line":"  if true_length > length then","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    failwith","counters":[{"col_start":4,"col_end":4,"count":0}]},{"line":"      \"Snark_keys_header.write_header: 2^expected_max_size_log2 is less than \\","counters":[]},{"line":"       the true length of the file\" ;","counters":[]},{"line":"  let true_length_string = string_of_int true_length in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  let true_length_padding =","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"    String.init","counters":[]},{"line":"      (String.length length_string - String.length true_length_string)","counters":[{"col_start":19,"col_end":19,"count":0},{"col_start":49,"col_end":49,"count":0}]},{"line":"      ~f:(fun _ -> ' ')","counters":[{"col_start":19,"col_end":19,"count":0}]},{"line":"  in","counters":[]},{"line":"  (* Go to where we wrote the data *)","counters":[]},{"line":"  Out_channel.seek out_channel (Int64.of_int length_data_offset) ;","counters":[{"col_start":2,"col_end":2,"count":0},{"col_start":43,"col_end":43,"count":0}]},{"line":"  (* Pad with spaces *)","counters":[]},{"line":"  Out_channel.output_string out_channel true_length_padding ;","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  (* Output the true length *)","counters":[]},{"line":"  Out_channel.output_string out_channel true_length_string ;","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  Out_channel.close out_channel","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"","counters":[]},{"line":"let read_with_header ~read_data filename =","counters":[]},{"line":"  let open Or_error.Let_syntax in","counters":[{"col_start":2,"col_end":2,"count":0}]},{"line":"  Or_error.try_with_join (fun () ->","counters":[]},{"line":"      (* We use [binary=true] to ensure that line endings aren't converted. *)","counters":[]},{"line":"      let in_channel = In_channel.create ~binary:true filename in","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      let file_length = In_channel.length in_channel |> Int.of_int64_exn in","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":56,"col_end":56,"count":0}]},{"line":"      let lexbuf = Lexing.from_channel in_channel in","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      let%bind header_json = parse_lexbuf lexbuf in","counters":[{"col_start":40,"col_end":40,"count":0}]},{"line":"      let%bind header =","counters":[]},{"line":"        of_yojson header_json |> Result.map_error ~f:Error.of_string","counters":[{"col_start":33,"col_end":33,"count":0},{"col_start":48,"col_end":48,"count":0}]},{"line":"      in","counters":[]},{"line":"      let offset = lexbuf.lex_curr_pos in","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      let%bind () =","counters":[]},{"line":"        In_channel.seek in_channel (Int64.of_int offset) ;","counters":[{"col_start":47,"col_end":47,"count":0}]},{"line":"        match In_channel.input_char in_channel with","counters":[{"col_start":8,"col_end":8,"count":0}]},{"line":"        | Some '\\n' ->","counters":[{"col_start":10,"col_end":10,"count":0}]},{"line":"            Ok ()","counters":[]},{"line":"        | None ->","counters":[{"col_start":10,"col_end":10,"count":0}]},{"line":"            Or_error.error_string","counters":[{"col_start":32,"col_end":32,"count":0}]},{"line":"              \"Incomplete header: the newline terminator is missing\"","counters":[]},{"line":"        | Some c ->","counters":[{"col_start":10,"col_end":10,"count":0}]},{"line":"            Or_error.error \"Header was not terminated by a newline character\"","counters":[{"col_start":25,"col_end":25,"count":0}]},{"line":"              (\"character\", c) [%sexp_of: string * char]","counters":[]},{"line":"      in","counters":[]},{"line":"      (* Bump offset for the newline terminator *)","counters":[]},{"line":"      let offset = offset + 1 in","counters":[{"col_start":6,"col_end":6,"count":0}]},{"line":"      In_channel.close in_channel ;","counters":[]},{"line":"      let%bind () =","counters":[]},{"line":"        if header.length = file_length then Ok ()","counters":[{"col_start":44,"col_end":44,"count":0}]},{"line":"        else","counters":[]},{"line":"          Or_error.error","counters":[{"col_start":10,"col_end":10,"count":0},{"col_start":23,"col_end":23,"count":0}]},{"line":"            \"Header length didn't match file length. Was the file only \\","counters":[]},{"line":"             partially downloaded?\"","counters":[]},{"line":"            ((\"header length\", header.length), (\"file length\", file_length))","counters":[]},{"line":"            [%sexp_of: (string * int) * (string * int)]","counters":[]},{"line":"      in","counters":[]},{"line":"      let%map data = Or_error.try_with (fun () -> read_data ~offset filename) in","counters":[{"col_start":37,"col_end":37,"count":0},{"col_start":50,"col_end":50,"count":0}]},{"line":"      (header, data) )","counters":[{"col_start":6,"col_end":6,"count":0},{"col_start":21,"col_end":21,"count":1}]}]}